{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dly27/stock-forecast/blob/main/stock_forecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aPdoQI48Q4E"
      },
      "source": [
        "# Stock Price Prediction using LSTM\n",
        "\n",
        "## Project Description\n",
        "This project aims to predict stock prices using an LSTM (Long Short-Term Memory) neural network. The dataset used is the historical stock prices of Apple Inc. (AAPL) from January 1, 2021, to January 1, 2024. The main steps involved in this analysis are:\n",
        "\n",
        "1. Fetching stock data from Alpha Vantage API\n",
        "2. Preprocessing the data and creating technical indicators (90-day and 30-day SMA)\n",
        "3. Use features such as : OHLCV , SMAs\n",
        "4. Splitting the data into training, validation, and testing sets\n",
        "5. Training an LSTM model on the preprocessed data\n",
        "6. Evaluating the model's performance on the testing set\n",
        "\n",
        "## To do\n",
        "\n",
        "\n",
        "1.   Expand the project scope: Include multiple stocks or a market index to demonstrate your ability to handle a larger and more diverse dataset.\n",
        "2.   Compare multiple models: Implement and compare the performance of different models to showcase your knowledge of various modeling techniques and your ability to select the most appropriate one for the task.\n",
        "3. Enhance model interpretation: Provide insights into the model's predictions, identify the most influential features, and discuss the economic or market factors that may impact the stock price.\n",
        "4. Improve visualizations: Create more informative and visually appealing charts and plots to effectively communicate your findings and make your project more engaging.\n",
        "5. Conduct error analysis: Analyze the model's errors, identify potential limitations, and propose strategies to improve the model's performance.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbMvH3WxH3RR"
      },
      "outputs": [],
      "source": [
        "!pip install alpha_vantage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "h3AfkF7SGt-C"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from alpha_vantage.timeseries import TimeSeries\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "ALPHA_VANTAGE_API_KEY = 'VC2S9T9RSVXMPOP0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lat7R_Kd-V1b"
      },
      "source": [
        "Functions to prepare data by creating features and targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5QNA_VtAG0TL"
      },
      "outputs": [],
      "source": [
        "def fetch_stock_data(symbol, start_date, end_date):\n",
        "    ts = TimeSeries(key=ALPHA_VANTAGE_API_KEY, output_format='pandas')\n",
        "    data, meta_data = ts.get_daily(symbol=symbol, outputsize='full')\n",
        "    data = data[(data.index >= start_date) & (data.index <= end_date)]\n",
        "    return data\n",
        "\n",
        "def prepare_data(data):\n",
        "    features = data[['1. open', '2. high', '3. low', '4. close', '5. volume', '90_day_sma', '30_day_sma']]\n",
        "    target = data['4. close']\n",
        "    return features, target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD4b7nLm-Ywt"
      },
      "source": [
        "* Use fetch_stock_data to fetch data from Alpha vantage\n",
        "* Calculate SMAs and handle missing values at end of SMAs\n",
        "* Prepare data for preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CKlS-vdDG2by"
      },
      "outputs": [],
      "source": [
        "#stock_data = fetch_stock_data('AAPL', '2021-01-01', '2024-01-01')\n",
        "\n",
        "stock_data['90_day_sma'] = stock_data['4. close'].rolling(window=90, min_periods=1).mean()\n",
        "stock_data['30_day_sma'] = stock_data['4. close'].rolling(window=30, min_periods=1).mean()\n",
        "\n",
        "last_valid_index = min(stock_data['90_day_sma'].last_valid_index(), stock_data['30_day_sma'].last_valid_index()) # Handles missing SMA values\n",
        "\n",
        "stock_data = stock_data.loc[:last_valid_index]\n",
        "\n",
        "features, target = prepare_data(stock_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vE5wFXr1dVSC"
      },
      "outputs": [],
      "source": [
        "print(stock_data.head)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcJDfg_o-gyI"
      },
      "source": [
        "* Plot stock data and SMAs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac9PfQkEez2R"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(stock_data.index, stock_data['4. close'])\n",
        "plt.plot(stock_data.index, stock_data['90_day_sma'])\n",
        "plt.plot(stock_data.index, stock_data['30_day_sma'])\n",
        "plt.title('Apple (AAPL) Stock Price')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price (USD)')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydiHjr7x-qPz"
      },
      "source": [
        "* Split data for training\n",
        "* Scale data\n",
        "* Reshape data to fit lstm model input"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "soSZa-cX_xfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "P6a1axCRHU19"
      },
      "outputs": [],
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(features, target, test_size=0.3, random_state=42, shuffle=False)\n",
        "X_validation, X_test, y_validation, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, shuffle=False)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "\n",
        "datasets = [X_train, X_validation, X_test]\n",
        "scaled_datasets = []\n",
        "for dataset in datasets:\n",
        "    scaled_dataset = pipeline.fit_transform(dataset)\n",
        "    scaled_datasets.append(scaled_dataset)\n",
        "\n",
        "X_train_scaled, X_validation_scaled, X_test_scaled = scaled_datasets\n",
        "\n",
        "# Create input sequences\n",
        "time_steps = 30\n",
        "step_size = 5\n",
        "\n",
        "X_train_lstm = []\n",
        "y_train_lstm = []\n",
        "\n",
        "for i in range(time_steps, len(X_train_scaled) - time_steps, step_size):\n",
        "    X_train_lstm.append(X_train_scaled[i:i + time_steps])\n",
        "    y_train_lstm.append(y_train[i + time_steps])\n",
        "\n",
        "X_train_lstm, y_train_lstm = np.array(X_train_lstm), np.array(y_train_lstm)\n",
        "X_train_lstm = X_train_lstm.reshape(X_train_lstm.shape[0], X_train_lstm.shape[1], X_train_lstm.shape[2])\n",
        "\n",
        "# Prepare validation and test sequences\n",
        "X_validation_lstm, y_validation_lstm = [], []\n",
        "X_test_lstm, y_test_lstm = [], []\n",
        "\n",
        "for i in range(time_steps, len(X_validation_scaled) - time_steps, step_size):\n",
        "    X_validation_lstm.append(X_validation_scaled[i:i + time_steps])\n",
        "    y_validation_lstm.append(y_validation[i + time_steps])\n",
        "\n",
        "for i in range(time_steps, len(X_test_scaled) - time_steps, step_size):\n",
        "    X_test_lstm.append(X_test_scaled[i:i + time_steps])\n",
        "    y_test_lstm.append(y_test[i + time_steps])\n",
        "\n",
        "X_validation_lstm, y_validation_lstm = np.array(X_validation_lstm), np.array(y_validation_lstm)\n",
        "X_test_lstm, y_test_lstm = np.array(X_test_lstm), np.array(y_test_lstm)\n",
        "\n",
        "X_validation_lstm = X_validation_lstm.reshape(X_validation_lstm.shape[0], X_validation_lstm.shape[1], X_validation_lstm.shape[2])\n",
        "X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], X_test_lstm.shape[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND_vIRT5_QzM"
      },
      "source": [
        "* Train model with early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSYevRW5HiVi"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1, clipvalue=1.0)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss',patience=10, verbose=1, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_lstm, y_train_lstm,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_validation_lstm, y_validation_lstm),\n",
        "    callbacks=[early_stopping]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2imOAbBm_WJW"
      },
      "source": [
        "Model prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "mEt-096j_Nyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3afca978-d900-4d09-fed3-5273d87b3bf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 14ms/step - loss: 622.4380\n",
            "2/2 [==============================] - 1s 11ms/step\n"
          ]
        }
      ],
      "source": [
        "X_test_lstm = []\n",
        "y_test_lstm = []\n",
        "\n",
        "for i in range(time_steps, len(X_test_scaled)):\n",
        "    X_test_lstm.append(X_test_scaled[i - time_steps:i])\n",
        "    y_test_lstm.append(y_test[i])\n",
        "\n",
        "X_test_lstm, y_test_lstm = np.array(X_test_lstm), np.array(y_test_lstm)\n",
        "X_test_lstm = X_test_lstm.reshape(X_test_lstm.shape[0], X_test_lstm.shape[1], X_test_lstm.shape[2])\n",
        "\n",
        "loss = model.evaluate(X_test_lstm, y_test_lstm)\n",
        "predictions = model.predict(X_test_lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "reb5YW8teAmU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "wRSPYFarB7UK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac682570-521d-4f58-e044-7f7eb382f17c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 797.943238225539\n",
            "Root Mean Squared Error (RMSE): 28.247889093267464\n",
            "Mean Absolute Error (MAE): 27.450905972184806\n",
            "Directional Accuracy: 0.0\n"
          ]
        }
      ],
      "source": [
        "mse = mean_squared_error(y_test_lstm, predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_test_lstm, predictions)\n",
        "directional_accuracy = np.sum((np.sign(y_test_lstm[1:] - y_test_lstm[:-1]) == np.sign(predictions[1:] - predictions[:-1]))) / len(y_test_lstm[1:])\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Directional Accuracy:\", directional_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot actual vs predicted price"
      ],
      "metadata": {
        "id": "vP_qj_zUfb64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_indices = stock_data.index[-len(y_test_lstm):]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(test_indices, y_test_lstm, label='Actual Price')\n",
        "plt.plot(test_indices, predictions, label='Predicted Price')\n",
        "plt.title('Stock Price Prediction')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Price (USD)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GYKHI4YveUqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "-L7OM-L_fak4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjiZoSyrw9Eqy16F+OleSu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}